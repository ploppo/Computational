{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "visible-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, make_scorer, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "import yaml\n",
    "from IPython.display import display  # to display variables in a \"nice\" way\n",
    "\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "\n",
    "pd.options.display.max_rows = 140\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "actual-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 296312+302736\n",
    "df_path = \"responses_hw.csv\" \n",
    "df = pd.read_csv(df_path)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-novelty",
   "metadata": {},
   "source": [
    "## Exercise 1: Loading and Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooked-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Country' 'Geography' 'Latino' 'Slow songs or fast songs' 'Chemistry']\n",
      "['Personality' 'Loneliness' 'Reliability' 'New environment' 'Fake'\n",
      " 'Heights' 'Internet usage' 'Prioritising workload' 'Interests or hobbies'\n",
      " 'Mood swings']\n"
     ]
    }
   ],
   "source": [
    "col_entertainment = list(df.columns)[0:63]\n",
    "col_personality = list(df.columns)[63:140]\n",
    "np.random.seed(rs)\n",
    "remove_entertainment = np.random.choice(col_entertainment,5)\n",
    "remove_personality = np.random.choice(col_personality,10)\n",
    "print(remove_entertainment)\n",
    "print(remove_personality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-coverage",
   "metadata": {},
   "source": [
    "## Exercise 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sound-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Smoking': {'never smoked': 1, 'tried smoking':2, 'former smoker':3, 'current smoker':4},\n",
    "        'Alcohol': {'never':1, 'social drinker': 2, 'drink a lot':3},\n",
    "        'Punctuality': {'early':1, 'on time':2, 'late':3},\n",
    "        'Lying': {'never':1, 'only to avoid hurting someone': 2, 'sometimes':3 ,'everytime it suits me':4},\n",
    "        'Internet usage': {'no time at all':1, 'less than an hour a day':2, 'few hours a day':3, 'most of the day':4}      \n",
    "       }\n",
    "df = df.replace(data)\n",
    "df_1 = df.iloc[:,0:63]\n",
    "df_2 = df.iloc[:, 63:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competent-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdf_1 = df_1.drop(columns=remove_entertainment)\n",
    "workdf_2 = df_2.drop(columns=remove_personality)\n",
    "workdf_tot = pd.concat((workdf_1, workdf_2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atomic-issue",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workdf_tot_na = workdf_tot.dropna()\n",
    "workdf_1_na = workdf_1.dropna()\n",
    "X_tot_na = workdf_tot_na.values\n",
    "X_1_na = workdf_1_na.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "multiple-hydrogen",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workdf_tot_0 = workdf_tot.fillna(value = 0)\n",
    "workdf_1_0 = workdf_1.fillna(value = 0)\n",
    "X_tot_0 = workdf_tot_0.values\n",
    "X_1_0 = workdf_1_0.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superior-blanket",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workdf_1_med = workdf_1.fillna(value = workdf_1.median(axis=0))\n",
    "workdf_tot_med = workdf_tot.fillna(value = workdf_tot.median(axis=0))\n",
    "X_tot_med = workdf_tot_med.values\n",
    "X_1_med = workdf_1_med.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-conversation",
   "metadata": {},
   "source": [
    "## Exercise 3: Computation of the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conservative-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df1 = {\"Data with deleted rows\" : X_1_na , \"Data with 0 instead of NaN\": X_1_0, \"Data with median instead of NaN\": X_1_med}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accomplished-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il minimo è 4\n",
      "Il minimo è 4\n",
      "Il minimo è 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Data with deleted rows': PCA(n_components=4),\n",
       " 'Data with 0 instead of NaN': PCA(n_components=4),\n",
       " 'Data with median instead of NaN': PCA(n_components=4)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggiungere roba al print\n",
    "dict_pca_1 = {}\n",
    "dict_y_1 = {}\n",
    "for k, v in dict_df1.items():\n",
    "    pca = PCA(n_components = 0.3)\n",
    "    pca.fit(v)\n",
    "    m = min(pca.n_components_, 5)\n",
    "    print('Il minimo è', m)\n",
    "    dict_pca_1[k] = (PCA(n_components = m))\n",
    "    dict_pca_1[k].fit(v)\n",
    "    dict_y_1[k] = dict_pca_1[k].transform(v)\n",
    "    \n",
    "    \n",
    "dict_pca_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-quest",
   "metadata": {},
   "source": [
    "Scelta della migliore PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "developmental-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score di sklearn -90.35279704771877 \n",
      "RMSE: 1.0337759010655552 \n",
      "score di sklearn -91.35677228705954 \n",
      "RMSE: 1.0547280944667912 \n",
      "score di sklearn -90.40681317076265 \n",
      "RMSE: 1.0352708627859404 \n"
     ]
    }
   ],
   "source": [
    "for k,v in dict_pca_1.items():\n",
    "    recon = v.inverse_transform(dict_y_1[k])\n",
    "    print(\"score di sklearn {} \".format(v.score(dict_df1[k])))\n",
    "    rmse = mean_squared_error(dict_df1[k], recon,squared=False)\n",
    "    print(\"RMSE: {} \".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "german-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1 = dict_pca_1[\"Data with deleted rows\"]\n",
    "X_1 = dict_df1[\"Data with deleted rows\"]\n",
    "Y_1 = dict_y_1[\"Data with deleted rows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hispanic-forestry",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb2f68d7c0a44c4adbe685b8531e98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dfbf8e510149c2a004f90c1292fc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    m = pca_1.n_components\n",
    "    # Curve of cumulative percentage of explained variance\n",
    "    plt.figure()\n",
    "    plt.plot(np.insert(np.cumsum(pca_1.explained_variance_ratio_), 0, 0))\n",
    "    plt.title(\"Data with deleted rows\")\n",
    "    plt.xticks(ticks=np.arange(1, m + 1), \n",
    "               labels=[f'PC{i}' for i in range(1, m + 1)])\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.ylabel('Cumulative explained variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    round_expl_var_ratio = np.round(pca_1.explained_variance_ratio_.sum() * 100, decimals=2)\n",
    "\n",
    "    # Barplot of percentage of explained variance\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.bar(range(1, m + 1), pca_1.explained_variance_ratio_)\n",
    "    plt.title(f\"PCs' EXPLAINED VARIANCE ({round_expl_var_ratio}% OF TOT. EXPL. VAR.)\")\n",
    "    plt.xticks(ticks=np.arange(1, m + 1), \n",
    "               labels=[f'PC{i}' for i in range(1, m + 1)],\n",
    "               rotation=45)\n",
    "    plt.xlabel('Principal Components')\n",
    "    plt.ylabel('Percentage of Explained variance')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-separation",
   "metadata": {},
   "source": [
    "## Exercise 4: Interpretation of the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "perceived-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_colors={} \n",
    " \n",
    "# Colors initialization for Music Preferences \n",
    "for el in list(workdf_1.columns)[:16]: \n",
    "    cat_colors[el]= 'tab:blue' \n",
    "     \n",
    "# Colors initialization for Movie Preferences \n",
    "for el in list(workdf_1.columns)[16:28]: \n",
    "    cat_colors[el]= 'tab:orange' \n",
    "\n",
    "# Colors initialization for Hobbies Interests \n",
    "for el in list(workdf_1.columns)[28:]: \n",
    "    cat_colors[el]= 'tab:green'\n",
    "     \n",
    "list_colors = [] \n",
    "for k,v in cat_colors.items(): \n",
    "    list_colors.append(cat_colors[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "charming-denver",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40edac60f7464560a02836d805db9cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC1 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: []\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Folk', 'Classical music', 'Musical', 'Swing, Jazz', 'Rock n roll', 'Alternative', 'Opera', 'Fantasy/Fairy tales', 'History', 'Psychology', 'Biology', 'Reading', 'Foreign languages', 'Medicine', 'Art exhibitions', 'Religion', 'Countryside, outdoors', 'Dancing', 'Musical instruments', 'Writing', 'Theatre']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977cecda7845400d9fb6ffeb025b3164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC2 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Metal or Hardrock', 'Punk', 'Horror', 'Thriller', 'Sci-fi', 'War', 'Western', 'Action', 'Politics', 'Mathematics', 'Physics', 'PC', 'Cars', 'Active sport', 'Science and technology', 'Adrenaline sports']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Romantic', 'Shopping']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1f909eab5b4edd8a1e95b04b4d0df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC3 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Dance', 'Pop', 'Hiphop, Rap', 'Techno, Trance', 'Romantic', 'Economy Management', 'Law', 'Cars', 'Dancing', 'Passive sport', 'Active sport', 'Celebrities', 'Shopping', 'Adrenaline sports', 'Pets']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Metal or Hardrock', 'Alternative']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60343805037d4ae589ad7d71292bbe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC4 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['History', 'Politics', 'Economy Management', 'Foreign languages', 'Law']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Rock', 'Metal or Hardrock', 'Punk', 'Fantasy/Fairy tales', 'Animated', 'Biology', 'Medicine', 'Pets']\n",
      "*********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(pca_1.n_components_):\n",
    "    # DEFINE EPSILON\n",
    "    eps = np.sqrt(1 / pca_1.n_features_)\n",
    "\n",
    "    plt.figure(figsize = (12, 6))\n",
    "    \n",
    "    # --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] ----------------\n",
    "    plt.plot([-0.5, pca_1.n_features_ - 0.5], [eps, eps], 'red')\n",
    "    plt.plot([-0.5, pca_1.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "    \n",
    "    plt.bar(np.arange(pca_1.n_features_), pca_1.components_[i, :], color = list_colors)  \n",
    "    plt.xticks(ticks = np.arange(pca_1.n_features_), \n",
    "                   labels = workdf_1_na.columns.to_list(),\n",
    "                   rotation = 90)\n",
    "    plt.title(f' YSP - PC{i+1}')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    # THE SELECTION OF THE SKILLS WITH CONTRIBUTE GREATER THAN THE THRESHOLD\n",
    "    ind_great_pos_PCii = np.argwhere(pca_1.components_[i, :] >= eps).flatten()\n",
    "    ind_great_neg_PCii = np.argwhere(pca_1.components_[i, :] <= -eps).flatten()\n",
    "    \n",
    "    great_pos_PCii = [list(workdf_1_na.columns)[i] for i in ind_great_pos_PCii]\n",
    "    great_neg_PCii = [list(workdf_1_na.columns)[i] for i in ind_great_neg_PCii]\n",
    "    \n",
    "    print('')\n",
    "    print(f'****************** PC{i+1} **********************')\n",
    "    print(f'HIGH-VALUED POSITIVE COMPONENTS: {great_pos_PCii}')\n",
    "    print('')\n",
    "    print(f'HIGH-VALUED NEGATIVE COMPONENTS: {great_neg_PCii}')\n",
    "    print('*********************************************')\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "broken-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_names = ['Artists', 'Geeks', 'Influencers', 'Preppy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "short-envelope",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aec4797befc47308ee3e091073221bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Score Graph\n",
    "fig_winescore = plt.figure(figsize=(8, 8))\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "ax.scatter(Y_1[:, 0], Y_1[:, 1], Y_1[:, 2])\n",
    "plt.title('YSP - SCORE GRAPH')\n",
    "ax.set_xlabel(pc_names[0])\n",
    "ax.set_ylabel(pc_names[1])\n",
    "ax.set_zlabel(pc_names[2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-southwest",
   "metadata": {},
   "source": [
    "## Exercise 5: k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stainless-sensitivity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# giocare con i parametri in modo furbo\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definizione delle liste di valori tra i quali \"scorrere\" per gli iper-parametri:\n",
    "#nclust_list = list(range(3, 11))\n",
    "#init_list = ['k-means++', 'random']\n",
    "#n_init_list = [3,10]\n",
    "#iter_list = [300, 500, 1000]\n",
    "\n",
    "#hparameters = {'n_clusters':nclust_list,'init': init_list, 'n_init':n_init_list, 'max_iter':iter_list} #dizionario\n",
    "#km = KMeans()\n",
    " \n",
    "#km_gs = GridSearchCV(estimator = km, \n",
    " #                     param_grid = hparameters, \n",
    "  #                    scoring = silhouette_score)\n",
    "\n",
    "#for y in dict_y_1.values():\n",
    " #   km_gs.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "olympic-communication",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** START k-MEANS WITH k=3 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=3 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=4 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=4 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=5 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=5 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=6 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=6 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=7 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=7 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=8 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=8 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=9 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=9 ******************\n",
      "\n",
      "****************** START k-MEANS WITH k=10 ******************\n",
      "Computing...\n",
      "****************** END k-MEANS WITH k=10 ******************\n",
      "\n",
      "\n",
      "\n",
      "****************** RESULTS OF THE SEARCH... ******************\n",
      "BEST SILHOUETTE SCORE: 0.21160769531553056 --> k = 3\n",
      "**************************************************************\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE SOME LISTS TO STORE THE TEMPORARY RESULTS AND, THEN, MAKE COMPARISONS\n",
    "\n",
    "# START THE FOR-CYCLE TO RUN THE k-MEANS AND MEASURING THE SILHOUETTE COEFFICIENT\n",
    "km_list = []\n",
    "silcoeff_list = []\n",
    "k_list = list(range(3, 11))\n",
    "\n",
    "for i in range(len(k_list)):\n",
    "    print(f'****************** START k-MEANS WITH k={k_list[i]} ******************')\n",
    "    print('Computing...')\n",
    "    km_list.append(KMeans(n_clusters=k_list[i], n_init=10, random_state=rs, max_iter = 10000)) \n",
    "    km = km_list[i]\n",
    "    km.fit(Y_1)\n",
    "    silcoeff_list.append(silhouette_score(Y_1, km.labels_))\n",
    "    print(f'****************** END k-MEANS WITH k={k_list[i]} ******************')\n",
    "    print('')\n",
    "\n",
    "# FIND THE BEST VALUE OF k AND THE BEST KMeans OBJECT\n",
    "i_best = np.argmax(silcoeff_list)\n",
    "k = k_list[i_best]\n",
    "km = km_list[i_best]\n",
    "\n",
    "# VISUALIZE THE RESULT\n",
    "print('')\n",
    "print('')\n",
    "print('****************** RESULTS OF THE SEARCH... ******************')\n",
    "print(f'BEST SILHOUETTE SCORE: {np.max(silcoeff_list)} --> k = {k}')\n",
    "print('**************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-engagement",
   "metadata": {},
   "source": [
    "## Excersice 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "printable-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = []\n",
    "markers_dict = {0: 'o', 1: '^', 2: 'x'}\n",
    "col_dict = {0:'blue', 1:'orange', 2:'green'}\n",
    "# Colors initialization for Music Preferences \n",
    "for el in km.labels_: \n",
    "    if el == 0:\n",
    "        cluster_colors.append('tab:blue')\n",
    "    if el == 1:\n",
    "        cluster_colors.append('tab:orange')\n",
    "    if el == 2:\n",
    "        cluster_colors.append('tab:green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "automatic-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab41a500e244ecda4335f75b78fd499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAKE THE 3D SCORE GRAPH WITH THE CENTROIDS\n",
    "sg_3d_km = plt.figure(figsize=(8, 8))\n",
    "ax_sg_3d_km = sg_3d_km.add_subplot(111, projection='3d')\n",
    "ax_sg_3d_km.scatter(Y_1[:, 0], Y_1[:, 1], Y_1[:, 2], c=cluster_colors, alpha=0.5)\n",
    "for i in range(0,3):\n",
    "    ax_sg_3d_km.scatter(km.cluster_centers_[i, 0], km.cluster_centers_[i, 1], km.cluster_centers_[i, 2],s=50, c='black', marker = markers_dict[i])\n",
    "plt.title('YPS - SCORE GRAPH')\n",
    "ax_sg_3d_km.set_xlabel(pc_names[0])\n",
    "ax_sg_3d_km.set_ylabel(pc_names[1])\n",
    "ax_sg_3d_km.set_zlabel(pc_names[2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "center-faculty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artists</th>\n",
       "      <th>Geeks</th>\n",
       "      <th>Influencers</th>\n",
       "      <th>Preppy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First centroid</th>\n",
       "      <td>0.822301</td>\n",
       "      <td>-2.822537</td>\n",
       "      <td>0.419510</td>\n",
       "      <td>-0.114976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second Centroid</th>\n",
       "      <td>-3.243089</td>\n",
       "      <td>0.816936</td>\n",
       "      <td>-0.047561</td>\n",
       "      <td>0.010363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Centroid</th>\n",
       "      <td>2.791118</td>\n",
       "      <td>2.083321</td>\n",
       "      <td>-0.393159</td>\n",
       "      <td>0.110776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Artists     Geeks  Influencers    Preppy\n",
       "First centroid   0.822301 -2.822537     0.419510 -0.114976\n",
       "Second Centroid -3.243089  0.816936    -0.047561  0.010363\n",
       "Third Centroid   2.791118  2.083321    -0.393159  0.110776"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = km.cluster_centers_, columns=pc_names, index = ['First centroid', 'Second Centroid', 'Third Centroid'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-colleague",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pretty-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il minimo è 6\n",
      "Il minimo è 6\n",
      "Il minimo è 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Data with deleted rows': PCA(n_components=6),\n",
       " 'Data with 0 instead of NaN': PCA(n_components=6),\n",
       " 'Data with median instead of NaN': PCA(n_components=6)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dftot = {\"Data with deleted rows\" : X_tot_na , \"Data with 0 instead of NaN\": X_tot_0, \"Data with median instead of NaN\": X_tot_med}\n",
    "\n",
    "# aggiungere roba al print\n",
    "dict_pca_tot = {}\n",
    "dict_y_tot = {}\n",
    "for k, v in dict_dftot.items():\n",
    "    pca = PCA(n_components = 0.3)\n",
    "    pca.fit(v)\n",
    "    m = min(pca.n_components_, 6)\n",
    "    print('Il minimo è', m)\n",
    "    dict_pca_tot[k] = (PCA(n_components = m))\n",
    "    dict_pca_tot[k].fit(v)\n",
    "    dict_y_tot[k] = dict_pca_tot[k].transform(v)\n",
    "    \n",
    "    \n",
    "dict_pca_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "synthetic-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score di sklearn -190.1314019147934 \n",
      "RMSE: 1.019763145942198 \n",
      "score di sklearn -192.71491868113216 \n",
      "RMSE: 1.0441634665589437 \n",
      "score di sklearn -190.85891019798072 \n",
      "RMSE: 1.0273410832031478 \n"
     ]
    }
   ],
   "source": [
    "for k,v in dict_pca_tot.items():\n",
    "    recon = v.inverse_transform(dict_y_tot[k])\n",
    "    print(\"score di sklearn {} \".format(v.score(dict_dftot[k])))\n",
    "    rmse = mean_squared_error(dict_dftot[k], recon,squared=False)\n",
    "    print(\"RMSE: {} \".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "wrong-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tot = dict_pca_tot[\"Data with deleted rows\"]\n",
    "X_tot = dict_dftot[\"Data with deleted rows\"]\n",
    "Y_tot = dict_y_tot[\"Data with deleted rows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dense-dressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11137e3356d74c089cd5210e45a868fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83642686fa0d4715ac949ad9f49ebecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = pca_tot.n_components\n",
    "# Curve of cumulative percentage of explained variance\n",
    "plt.figure()\n",
    "plt.plot(np.insert(np.cumsum(pca_tot.explained_variance_ratio_), 0, 0))\n",
    "plt.title(k)\n",
    "plt.xticks(ticks=np.arange(1, m + 1), \n",
    "               labels=[f'PC{i}' for i in range(1, m + 1)])\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "    \n",
    "round_expl_var_ratio = np.round(pca_tot.explained_variance_ratio_.sum() * 100, decimals=2)\n",
    "\n",
    "# Barplot of percentage of explained variance\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(range(1, m + 1), pca_tot.explained_variance_ratio_)\n",
    "plt.title(f\"PCs' EXPLAINED VARIANCE ({round_expl_var_ratio}% OF TOT. EXPL. VAR.)\")\n",
    "plt.xticks(ticks=np.arange(1, m + 1), \n",
    "               labels=[f'PC{i}' for i in range(1, m + 1)],\n",
    "               rotation=45)\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Percentage of Explained variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-bible",
   "metadata": {},
   "source": [
    "## Exercise 9: Interpretation of the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bronze-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_colors={} \n",
    " \n",
    "# Colors initialization for Music Preferences \n",
    "for el in list(workdf_tot.columns)[:16]: \n",
    "    cat_colors[el]= 'tab:blue' \n",
    "    \n",
    "# Colors initialization for Movie Preferences \n",
    "for el in list(workdf_tot.columns)[16:28]: \n",
    "    cat_colors[el]= 'tab:orange' \n",
    "\n",
    "# Colors initialization for Hobbies Interests \n",
    "for el in list(workdf_tot.columns)[28:58]: \n",
    "    cat_colors[el]= 'tab:green'\n",
    "\n",
    "# Colors initialization for Phobias\n",
    "for el in list(workdf_tot.columns)[58:67]: \n",
    "    cat_colors[el]= 'tab:purple'\n",
    "    \n",
    "# Colors initialization Health Habits \n",
    "for el in list(workdf_tot.columns)[67:70]: \n",
    "    cat_colors[el]= 'tab:red'\n",
    "          \n",
    "# Colors initialization Personality Traits, Views on Life, and Opinions\n",
    "for el in list(workdf_tot.columns)[70: 119]: \n",
    "    cat_colors[el]= 'gold'\n",
    "    cat_colors={}\n",
    "    \n",
    "# Colors initialization for Music Preferences \n",
    "for el in list(workdf_tot.columns)[:16]: \n",
    "    cat_colors[el]= 'tab:blue' \n",
    "    \n",
    "# Colors initialization for Movie Preferences \n",
    "for el in list(workdf_tot.columns)[16:28]: \n",
    "    cat_colors[el]= 'tab:orange' \n",
    "\n",
    "# Colors initialization for Hobbies Interests \n",
    "for el in list(workdf_tot.columns)[28:58]: \n",
    "    cat_colors[el]= 'tab:green'\n",
    "\n",
    "# Colors initialization for Phobias\n",
    "for el in list(workdf_tot.columns)[58:67]: \n",
    "    cat_colors[el]= 'tab:purple'\n",
    "    \n",
    "# Colors initialization Health Habits \n",
    "for el in list(workdf_tot.columns)[67:70]: \n",
    "    cat_colors[el]= 'tab:red'\n",
    "          \n",
    "# Colors initialization Personality Traits, Views on Life, and Opinions\n",
    "for el in list(workdf_tot.columns)[70: 119]: \n",
    "    cat_colors[el]= 'gold'\n",
    "    \n",
    "# Colors initialization Spending Habits\n",
    "for el in list(workdf_tot.columns)[119:]: \n",
    "    cat_colors[el]= 'turquoise'\n",
    "    \n",
    "list_colors = [] \n",
    "for k,v in cat_colors.items(): \n",
    "    list_colors.append(cat_colors[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "peripheral-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5274e226b954d2cb9f886248ed3389a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC1 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Metal or Hardrock', 'Horror', 'Thriller', 'Sci-fi', 'War', 'Western', 'Action', 'PC', 'Cars', 'Science and technology', 'Adrenaline sports', 'Small - big dogs', 'Spending on gadgets']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Musical', 'Romantic', 'Fantasy/Fairy tales', 'Animated', 'Psychology', 'Biology', 'Reading', 'Foreign languages', 'Medicine', 'Art exhibitions', 'Religion', 'Dancing', 'Musical instruments', 'Writing', 'Gardening', 'Celebrities', 'Shopping', 'Theatre', 'Storm', 'Darkness', 'Spiders', 'Snakes', 'Rats', 'Dangerous dogs', 'Writing notes', 'Workaholism', 'Final judgement', 'Empathy', 'Giving', 'God', 'Children', 'Life struggles', 'Finding lost valuables', 'Shopping centres']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e6b0e7aee4a0a9fc8fb79e92c5ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC2 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Pop', 'Celebrities', 'Shopping', 'Spiders', 'Snakes', 'Rats', 'Dangerous dogs', 'Public speaking', 'Shopping centres', 'Spending on looks']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Folk', 'Classical music', 'Musical', 'Rock', 'Metal or Hardrock', 'Punk', 'Swing, Jazz', 'Rock n roll', 'Alternative', 'Opera', 'Sci-fi', 'War', 'Documentary', 'Western', 'History', 'Psychology', 'Politics', 'Mathematics', 'Physics', 'Biology', 'Reading', 'Medicine', 'Art exhibitions', 'Religion', 'Countryside, outdoors', 'Musical instruments', 'Writing', 'Science and technology', 'Theatre', 'Workaholism', 'Elections']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d65db025aa472ab4a976ba53500eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC3 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Metal or Hardrock', 'Fear of public speaking', 'Public speaking']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Dance', 'Pop', 'Hiphop, Rap', 'Techno, Trance', 'Action', 'Politics', 'Economy Management', 'Law', 'Cars', 'Dancing', 'Passive sport', 'Active sport', 'Celebrities', 'Shopping', 'Science and technology', 'Fun with friends', 'Adrenaline sports', 'Pets', 'Daily events', 'Giving', 'Cheating in school', 'Number of friends', 'Appearence and gestures', 'Socializing', 'Assertiveness', 'Knowing the right people', 'Energy levels', 'Shopping centres', 'Branded clothing', 'Entertainment spending', 'Spending on looks', 'Spending on gadgets', 'Spending on healthy eating']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6800d39632f34798a34c891752418ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC4 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Rock', 'Metal or Hardrock', 'Punk', 'Swing, Jazz', 'Rock n roll', 'Alternative', 'Horror', 'Reading', 'Art exhibitions', 'Writing', 'Theatre', 'Darkness', 'Spiders', 'Ageing', 'Smoking', 'Loss of interest', 'Criminal damage', 'Hypochondria', 'Cheating in school', 'Changing the past', 'Getting angry', 'Small - big dogs', 'Getting up', 'Entertainment spending']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Dance', 'Mathematics', 'Physics', 'Biology', 'Cars', 'Religion', 'Gardening', 'Writing notes', 'Workaholism', 'Thinking ahead', 'Final judgement', 'God', 'Children', 'Finding lost valuables', 'Finances']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-5f243036de0c>:5: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize = (18, 25))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be313e2b16b4daa9eae85931bd716e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC5 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['Dancing', 'Elections', 'Number of friends', 'Socializing', 'Energy levels', 'Small - big dogs', 'Entertainment spending']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Metal or Hardrock', 'Punk', 'Techno, Trance', 'Horror', 'Thriller', 'Sci-fi', 'War', 'Documentary', 'Western', 'Action', 'Mathematics', 'Physics', 'Internet', 'PC', 'Cars', 'Science and technology', 'Flying', 'Spiders', 'Snakes', 'Rats', 'Ageing', 'Dangerous dogs', 'Fear of public speaking', 'Thinking ahead', 'Criminal damage', 'Decision making', 'Self-criticism', 'Hypochondria', 'Eating to survive', 'Health', 'Changing the past', 'Public speaking', 'Finances', 'Spending on gadgets']\n",
      "*********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ed3ed92918483dacba34cab7a06075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** PC6 **********************\n",
      "HIGH-VALUED POSITIVE COMPONENTS: ['History', 'Politics', 'Economy Management', 'Law', 'Snakes', 'Rats', 'Dangerous dogs', 'Daily events', 'Writing notes', 'Workaholism', 'Thinking ahead', 'Elections', 'Self-criticism', 'Getting angry', 'Knowing the right people', 'Branded clothing']\n",
      "\n",
      "HIGH-VALUED NEGATIVE COMPONENTS: ['Rock', 'Metal or Hardrock', 'Punk', 'Reggae, Ska', 'Rock n roll', 'Fantasy/Fairy tales', 'Animated', 'Biology', 'Medicine', 'Countryside, outdoors', 'Passive sport', 'Active sport', 'Gardening', 'Adrenaline sports', 'Pets', 'Compassion to animals', 'Life struggles']\n",
      "*********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(pca_tot.n_components_):\n",
    "    # DEFINE EPSILON\n",
    "    eps = np.sqrt(1 / pca_tot.n_features_)\n",
    "\n",
    "    plt.figure(figsize = (18, 25))\n",
    "    \n",
    "    # --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] ----------------\n",
    "    plt.plot([eps, eps], [-0.5, pca_tot.n_features_ - 0.5], 'red')\n",
    "    plt.plot([-eps, -eps], [-0.5, pca_tot.n_features_ - 0.5], 'red')\n",
    "    \n",
    "    plt.barh(np.arange(pca_tot.n_features_), pca_tot.components_[i, :], color = list_colors)  \n",
    "    plt.yticks(ticks = np.arange(pca_tot.n_features_), \n",
    "                   labels = workdf_tot.columns.to_list())\n",
    "    plt.title(f' YSP - PC{i+1}')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # THE SELECTION OF THE SKILLS WITH CONTRIBUTE GREATER THAN THE THRESHOLD\n",
    "    ind_great_pos_PCii = np.argwhere(pca_tot.components_[i, :] >= eps).flatten()\n",
    "    ind_great_neg_PCii = np.argwhere(pca_tot.components_[i, :] <= -eps).flatten()\n",
    "    \n",
    "    great_pos_PCii = [list(workdf_tot.columns)[i] for i in ind_great_pos_PCii]\n",
    "    great_neg_PCii = [list(workdf_tot.columns)[i] for i in ind_great_neg_PCii]\n",
    "    \n",
    "    print('')\n",
    "    print(f'****************** PC{i+1} **********************')\n",
    "    print(f'HIGH-VALUED POSITIVE COMPONENTS: {great_pos_PCii}')\n",
    "    print('')\n",
    "    print(f'HIGH-VALUED NEGATIVE COMPONENTS: {great_neg_PCii}')\n",
    "    print('*********************************************')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-animal",
   "metadata": {},
   "source": [
    "## Exercise 10: k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-fifteen",
   "metadata": {},
   "source": [
    "## Exercise 11: Centroid Interpretation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-ballot",
   "metadata": {},
   "source": [
    "## Exercise 12: Centroids Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
